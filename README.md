# ğŸ“ Web-Based File Processing App

This project is a complete web application that allows users to:

- Upload CSV or Excel files via a web interface
- Queue file processing as a background job using Celery
- Store files in Google Cloud Storage (GCS)
- Receive job status and results via email
- Track job status through a status page

---

## âš™ï¸ Tech Stack

### Backend

- **FastAPI** â€“ High-performance API framework
- **Celery** â€“ Asynchronous task queue
- **Redis** â€“ Message broker for Celery
- **SQLite** â€“ Lightweight relational database
- **Pandas / openpyxl** â€“ File parsing and data analysis
- **Google Cloud Storage (GCS)** â€“ File storage
- **aiosmtplib** â€“ Email sending (async)
- **python-dotenv / Pydantic** â€“ Configuration handling

### Frontend

- **HTML + CSS**
- **Vanilla JavaScript**

---

## ğŸ“‚ Folder Structure

```
my_project/
â”‚
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ worker/                  # Celery worker setup
â”‚   â”œâ”€â”€ celery_worker.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ frontend/                # Static web frontend
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ status.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”‚
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ docker-compose.yml       # (Optional) for unified Docker setup
â””â”€â”€ README.md                # (You're here)
```

---

## ğŸš€ Running the Project (Locally)

### Prerequisites

- Python 3.10+
- Redis server (for local development)
- Google Cloud credentials set up locally

---

### Backend

1. Navigate to the backend directory:
   ```bash
   cd backend
   ```

2. Create a virtual environment and install dependencies:
   ```bash
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

3. Add a `.env` file inside `backend/`:
   ```env
   CELERY_BROKER_URL=redis://localhost:6379/0
   CELERY_RESULT_BACKEND=redis://localhost:6379/0
   GCS_BUCKET_NAME=your-gcs-bucket
   EMAIL_SENDER=your@email.com
   ```

4. Start the FastAPI server:
   ```bash
   uvicorn app.main:app --reload
   ```

5. Start the Celery worker (in another terminal):
   ```bash
   cd backend
   celery -A app.core.celery_app.celery_app worker --loglevel=info
   ```

### Frontend

Just open `frontend/index.html` and `frontend/status.html` in your browser.

No build step is needed â€” it's pure HTML, CSS, and JS.

---

## ğŸ³ Docker Setup (Optional)

Make sure Docker and Docker Compose are installed.

Add a `docker-compose.yml` in the root (if not already):

```yaml
version: '3'

services:
  redis:
    image: redis
    ports:
      - "6379:6379"

  backend:
    build: ./backend
    volumes:
      - ./backend:/app
    ports:
      - "8000:8000"
    depends_on:
      - redis
    env_file:
      - ./backend/.env

  worker:
    build: ./worker
    volumes:
      - ./backend:/app
    depends_on:
      - redis
    env_file:
      - ./backend/.env
```

Run everything:
```bash
docker-compose up --build
```

---

## ğŸ”§ Features & Flow

1. User uploads a file at `/upload`.
2. Backend uploads the file to GCS and queues a background job in Redis via Celery.
3. The Celery worker downloads the file from GCS, processes it, and stores the result.
4. Once done, the worker sends an email to the user.
5. Meanwhile, users can check status via `/status`.

---

## âœ… TODO / Future Improvements

- Add user login/auth (to associate jobs with users)
- Improve progress feedback on frontend
- Use PostgreSQL for production-grade data
- Dashboard UI for job history and results
- Unit tests for tasks and API routes

---

## ğŸ“§ Maintainer

Built with â¤ï¸ by [Mayur Bodhare]  